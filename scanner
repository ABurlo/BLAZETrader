import os
import pickle
from datetime import datetime, timedelta
import asyncio
import nest_asyncio
from pytz import UTC
import logging
from logging.handlers import RotatingFileHandler
from ib_insync import IB, Stock, util
import pandas as pd
import numpy as np
from typing import Optional, List, Dict, Tuple, Any

# Configure logging
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_file = 'trading_system.log'
log_handler = RotatingFileHandler(log_file, maxBytes=5*1024*1024, backupCount=3)
log_handler.setFormatter(log_formatter)

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(log_handler)
console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)
logger.addHandler(console_handler)
nest_asyncio.apply()

class DataCache:
    """Handles caching of historical market data to reduce API calls."""
    
    def __init__(self, cache_dir: str = './cache'):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

    def get_cache_path(self, symbol: str, timeframe: str) -> str:
        return os.path.join(self.cache_dir, f'{symbol}_{timeframe}.pickle')

    def is_cached(self, symbol: str, timeframe: str) -> bool:
        cache_path = self.get_cache_path(symbol, timeframe)
        return os.path.exists(cache_path)

    def load_cache(self, symbol: str, timeframe: str) -> pd.DataFrame:
        try:
            with open(self.get_cache_path(symbol, timeframe), 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            logger.error(f"Error loading cache for {symbol}_{timeframe}: {e}")
            return pd.DataFrame()

    def save_cache(self, symbol: str, timeframe: str, data: pd.DataFrame) -> None:
        try:
            with open(self.get_cache_path(symbol, timeframe), 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            logger.error(f"Error saving cache for {symbol}_{timeframe}: {e}")

class MarketScanner:
    """Scans the market for trading setups based on fair value gaps (FVG)."""
    
    def __init__(self, host: str = '127.0.0.1', port: int = 7497, client_id: int = 1):
        self.ib = IB()
        self.host = host
        self.port = port
        self.client_id = client_id
        self.fee_per_share = 0.0035
        self.max_slippage_percent = 0.02
        self.cache = DataCache()
        self._connected = False

    async def connect(self, retries: int = 3) -> bool:
        """Connect to Interactive Brokers TWS or Gateway."""
        for attempt in range(retries):
            try:
                if not self.ib.isConnected():
                    await self.ib.connectAsync(self.host, self.port, clientId=self.client_id)
                    self._connected = True
                    logger.info(f"Connected to Interactive Brokers at {self.host}:{self.port}")
                    return True
                else:
                    self._connected = True
                    logger.info("Already connected to Interactive Brokers")
                    return True
            except Exception as e:
                logger.error(f"Connection attempt {attempt + 1} failed: {e}")
                if attempt < retries - 1:
                    await asyncio.sleep(2)
        
        logger.error("Failed to connect after retries")
        self._connected = False
        return False

    def disconnect(self) -> None:
        """Disconnect from Interactive Brokers TWS or Gateway."""
        try:
            if self.ib.isConnected():
                self.ib.disconnect()
                logger.info("Disconnected from Interactive Brokers")
            self._connected = False
        except Exception as e:
            logger.error(f"Disconnect failed: {e}")
            self._connected = False

    async def get_historical_data(self, symbol: str, end_date: datetime, 
                                 duration: str, bar_size: str) -> Optional[pd.DataFrame]:
        """Fetch historical data for a symbol with technical indicators."""
        # Check cache first
        if self.cache.is_cached(symbol, bar_size):
            df = self.cache.load_cache(symbol, bar_size)
            if not df.empty:
                return df

        try:
            contract = Stock(symbol, 'SMART', 'USD')
            
            # Ensure duration is in the correct format: integer{SPACE}unit
            if duration[0].isdigit() and ' ' not in duration:
                # Find the position where digits end
                for i, char in enumerate(duration):
                    if not char.isdigit():
                        # Insert a space between number and unit
                        duration = duration[:i] + ' ' + duration[i:]
                        break
            
            bars = await self.ib.reqHistoricalDataAsync(
                contract, end_date, duration, bar_size, 'TRADES', useRTH=True
            )
            
            if not bars:
                logger.warning(f"No historical data available for {symbol}")
                return None

            # Convert to DataFrame and process
            df = util.df(bars)
            df['date'] = pd.to_datetime(df['date'], utc=True, errors='coerce')
            
            if df['date'].isna().any():
                logger.error(f"Date parsing failed for {symbol}")
                return None
                
            df.set_index('date', inplace=True)
            
            # Calculate ATR
            df['atr'] = self._calculate_atr(df)
            
            # Add additional indicators for daily timeframe
            if bar_size == '1 day':
                self._add_daily_indicators(df)

            # Cache the data
            self.cache.save_cache(symbol, bar_size, df)
            return df
            
        except Exception as e:
            logger.error(f"Failed to fetch historical data for {symbol}: {e}")
            return None

    def _calculate_atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average True Range."""
        # Calculate true range components
        high_low = df['high'] - df['low']
        high_close_prev = abs(df['high'] - df['close'].shift(1))
        low_close_prev = abs(df['low'] - df['close'].shift(1))
        
        # Combine components to get true range
        # Use pandas max method instead of numpy.maximum.reduce
        true_range = pd.DataFrame({
            'hl': high_low,
            'hcp': high_close_prev,
            'lcp': low_close_prev
        }).max(axis=1)
        
        # Apply rolling mean to the pandas Series
        return true_range.rolling(window=period, min_periods=1).mean()

    def _add_daily_indicators(self, df: pd.DataFrame) -> None:
        """Add technical indicators to daily data."""
        # Simple Moving Average and its slope
        df['sma_20'] = df['close'].rolling(window=20, min_periods=1).mean()
        df['sma_slope'] = df['sma_20'].diff()
        
        # Directional Movement Index components
        df['plus_di'] = 100 * (df['high'].diff().clip(lower=0) / df['atr']).rolling(14, min_periods=1).mean()
        df['minus_di'] = 100 * ((-df['low'].diff().clip(upper=0)) / df['atr']).rolling(14, min_periods=1).mean()
        
        # Average Directional Index
        df['adx'] = 100 * abs(df['plus_di'] - df['minus_di']) / (df['plus_di'] + df['minus_di']).replace(0, np.nan).rolling(14, min_periods=1).mean()
        
        # Bollinger Band Width
        std_20 = df['close'].rolling(20, min_periods=1).std()
        df['bb_width'] = (df['sma_20'] + 2 * std_20 - (df['sma_20'] - 2 * std_20)) / df['sma_20']

    async def get_5min_data(self, symbol: str, start_time: datetime, end_date: datetime) -> Optional[pd.DataFrame]:
        """Get 5-minute bar data for a symbol."""
        if self.cache.is_cached(symbol, '5min'):
            df = self.cache.load_cache(symbol, '5min')
            if not df.empty and any(df.index >= start_time):
                return df[df.index >= start_time]

        # Use a standard duration format instead of bars
        # Calculate days between dates and add some buffer
        days_diff = (end_date - start_time).days + 1
        duration = f"{max(days_diff, 7)} D"  # At least 7 days
        
        df = await self.get_historical_data(symbol, end_date, duration, '5 mins')
        return df[df.index >= start_time] if df is not None and not df.empty else None

    def find_fvg(self, df: pd.DataFrame, current_index: int) -> List[Tuple[Any, float, float]]:
        """Find Fair Value Gaps in the data with improved detection and debugging."""
        fvgs = []
        potential_fvgs = 0
        
        for i in range(2, current_index + 1):
            # Bullish FVG: Current candle's low is higher than previous-1 candle's high
            if (df['low'].iloc[i] > df['high'].iloc[i-2]):
                potential_fvgs += 1
                # Check for strong momentum
                if df['close'].iloc[i-1] > df['open'].iloc[i-1]:  # Previous candle is bullish
                    fvgs.append((df.index[i-1], df['high'].iloc[i-2], df['low'].iloc[i]))
                # Alternative pattern: strong bullish candle after the gap
                elif i < current_index and df['close'].iloc[i] > df['open'].iloc[i] * 1.005:
                    fvgs.append((df.index[i], df['high'].iloc[i-2], df['low'].iloc[i]))
        
        if current_index >= 100 and current_index % 100 == 0:
            logger.debug(f"FVG detection at index {current_index}: Found {len(fvgs)} valid FVGs out of {potential_fvgs} potential gaps")
            
        return fvgs

    def has_rejection_candle(self, df: pd.DataFrame, fvg: Tuple[Any, float, float], current_index: int) -> bool:
        """Enhanced rejection candle detection with debugging."""
        candle = df.iloc[current_index]
        prev_candle = df.iloc[current_index-1] if current_index > 0 else None
        
        # Check conditions individually for debugging
        close_in_fvg = fvg[1] <= candle['close'] <= fvg[2]
        is_bullish = candle['close'] > candle['open']
        tested_below = (candle['low'] < fvg[1] or candle['open'] < fvg[1])
        strong_close = candle['high'] - candle['close'] < 0.3 * (candle['high'] - candle['low'])
        
        # Log detailed rejection candle analysis periodically
        if current_index % 100 == 0:
            logger.debug(f"Rejection candle check at index {current_index}: "
                        f"Close in FVG: {close_in_fvg}, Bullish: {is_bullish}, "
                        f"Tested below: {tested_below}, Strong close: {strong_close}")
        
        # Add volume confirmation if available
        volume_confirmation = True
        if 'volume' in df.columns and prev_candle is not None:
            volume_confirmation = candle['volume'] > prev_candle['volume']
            
        rejection_pattern = close_in_fvg and is_bullish and tested_below and strong_close
        
        return rejection_pattern and volume_confirmation
    
    def has_closing_into_fvg(self, df: pd.DataFrame, fvg: Tuple[Any, float, float], current_index: int) -> bool:
        """Check if candle closes inside the FVG without penetrating through."""
        candle = df.iloc[current_index]
        
        # Check if price entered the FVG
        entered_fvg = (candle['low'] <= fvg[2] and candle['high'] >= fvg[1])
        
        # Check if price closed inside the FVG
        closed_in_fvg = (fvg[1] <= candle['close'] <= fvg[2])
        
        # Check that price didn't penetrate through the entire FVG
        not_penetrated = not (candle['low'] <= fvg[1] and candle['high'] >= fvg[2])
        
        return entered_fvg and closed_in_fvg and not_penetrated

    def is_unmitigated(self, df: pd.DataFrame, fvg: Tuple[Any, float, float], current_index: int) -> bool:
        """Check if a Fair Value Gap has not been mitigated."""
        subset = df.loc[fvg[0]:df.index[current_index]]
        # FVG is mitigated if price has traded through the gap
        return not ((subset['low'] <= fvg[1]) & (subset['high'] >= fvg[2])).any()

    def has_rejection_candle(self, df: pd.DataFrame, fvg: Tuple[Any, float, float], current_index: int) -> bool:
        """Enhanced rejection candle detection with volume confirmation."""
        candle = df.iloc[current_index]
        prev_candle = df.iloc[current_index-1] if current_index > 0 else None
        
        # Check for bullish rejection with volume confirmation
        rejection_pattern = (
            fvg[1] <= candle['close'] <= fvg[2] and  # Close within FVG
            candle['close'] > candle['open'] and      # Bullish candle
            (candle['low'] < fvg[1] or candle['open'] < fvg[1]) and  # Tested below FVG
            candle['high'] - candle['close'] < 0.3 * (candle['high'] - candle['low'])  # Strong close
        )
        
        # Add volume confirmation if available
        volume_confirmation = True
        if 'volume' in df.columns and prev_candle is not None:
            volume_confirmation = candle['volume'] > prev_candle['volume']
            
        return rejection_pattern and volume_confirmation

    def has_volume_confirmation(self, df: pd.DataFrame, current_index: int, lookback: int = 5) -> bool:
        """Check if current volume is higher than recent average volume."""
        if 'volume' not in df.columns or current_index < lookback:
            return False
            
        current_volume = df['volume'].iloc[current_index]
        avg_volume = df['volume'].iloc[current_index-lookback:current_index].mean()
        
        return current_volume > avg_volume * 1.2  # 20% higher than average

    def has_ma_alignment(self, df: pd.DataFrame, current_index: int) -> bool:
        """Check if moving averages are aligned in favor of the trade direction."""
        if 'sma_20' not in df.columns or 'sma_50' not in df.columns:
            return False
        
        # For bullish setups
        if df['close'].iloc[current_index] > df['open'].iloc[current_index]:
            return (df['sma_20'].iloc[current_index] > df['sma_50'].iloc[current_index] and
                    df['close'].iloc[current_index] > df['sma_20'].iloc[current_index])
        
        # For bearish setups
        else:
            return (df['sma_20'].iloc[current_index] < df['sma_50'].iloc[current_index] and
                    df['close'].iloc[current_index] < df['sma_20'].iloc[current_index])

    def calculate_rsi(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Relative Strength Index."""
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = -delta.where(delta < 0, 0).rolling(window=period).mean()
        
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def has_rsi_confirmation(self, df: pd.DataFrame, current_index: int) -> bool:
        """Check if RSI confirms the potential trade direction."""
        if 'rsi' not in df.columns:
            df['rsi'] = self.calculate_rsi(df)
        
        rsi = df['rsi'].iloc[current_index]
        
        # For bullish setups - RSI showing strength but not overbought
        if df['close'].iloc[current_index] > df['open'].iloc[current_index]:
            return 40 < rsi < 70
        
        # For bearish setups - RSI showing weakness but not oversold
        else:
            return 30 < rsi < 60
        
    def has_higher_timeframe_alignment(self, symbol: str, current_time: datetime, setup_direction: str) -> bool:
        """Check if higher timeframe trend aligns with the setup direction."""
        try:
            # Get daily data
            daily_df = asyncio.run(self.get_historical_data(
                symbol, current_time, '30 D', '1 day'
            ))
            
            if daily_df is None or daily_df.empty:
                return False
                
            # Get trend direction on daily timeframe
            trend, _ = self.get_trend_direction(daily_df, current_time)
            
            # Check alignment
            return (setup_direction == 'bullish' and trend == 'up') or \
                (setup_direction == 'bearish' and trend == 'down')
                
        except Exception as e:
            logger.error(f"Error checking higher timeframe alignment: {e}")
            return False

    def has_bos(self, df: pd.DataFrame, current_index: int, lookback: int = 10) -> bool:
        """Check if there's a breakout of structure in recent candles."""
        start_idx = max(1, current_index - lookback)
        for i in range(start_idx, current_index):
            if df['close'].iloc[i] > df['high'].iloc[i-1]:
                return True
        return False

    def get_trend_direction(self, daily_df: pd.DataFrame, current_date: datetime) -> Tuple[str, str]:
        """Determine market trend and regime with more relaxed conditions and debugging."""
        subset = daily_df[daily_df.index <= current_date]
        if len(subset) < 20:
            logger.debug(f"Insufficient data for trend detection: {len(subset)} candles")
            return 'neutral', 'unknown'
        
        # Check trend conditions
        price_above_sma = subset['close'].iloc[-1] > subset['sma_20'].iloc[-1]
        price_higher_than_recent = subset['close'].iloc[-1] > subset['close'].iloc[-5]
        price_below_sma = subset['close'].iloc[-1] < subset['sma_20'].iloc[-1]
        price_lower_than_recent = subset['close'].iloc[-1] < subset['close'].iloc[-5]
        
        # More relaxed trend determination
        trend = 'neutral'
        if price_above_sma or price_higher_than_recent:
            trend = 'up'
        elif price_below_sma and price_lower_than_recent:
            trend = 'down'
        
        # Check regime conditions
        bb_width_current = subset['bb_width'].iloc[-1]
        bb_width_threshold = subset['bb_width'].quantile(0.3)
        is_trending = bb_width_current > bb_width_threshold
        
        # Accept both trending and ranging regimes
        regime = 'trending' if is_trending else 'ranging'
        
        # Log trend analysis periodically
        if current_date.day % 5 == 0 and current_date.hour == 10:
            logger.debug(f"Trend analysis for {current_date}: "
                        f"Above SMA: {price_above_sma}, Higher than recent: {price_higher_than_recent}, "
                        f"Below SMA: {price_below_sma}, Lower than recent: {price_lower_than_recent}, "
                        f"BB Width: {bb_width_current:.4f} vs Threshold: {bb_width_threshold:.4f}, "
                        f"Result: Trend={trend}, Regime={regime}")
        
        return trend, regime

    def is_potential_trend(self, df: pd.DataFrame) -> bool:
        """Alternative trend detection with relaxed conditions."""
        # Check if price is above 20-day SMA
        above_sma = df['close'].iloc[-1] > df['sma_20'].iloc[-1]
        
        # Check if 20-day SMA is higher than 50-day SMA (if available)
        sma_50 = df['close'].rolling(window=50, min_periods=1).mean().iloc[-1]
        sma_alignment = df['sma_20'].iloc[-1] > sma_50
        
        # Check for higher lows in recent price action
        recent_lows = df['low'].iloc[-10:].rolling(window=3).min()
        higher_lows = recent_lows.is_monotonic_increasing
        
        # Return true if at least 2 of 3 conditions are met
        conditions_met = sum([above_sma, sma_alignment, higher_lows])
        return conditions_met >= 2

    def calculate_targets_and_trailing_sl(self, entry_price: float, initial_sl: float, atr: float) -> Tuple[float, float, float]:
        """Calculate profit targets based on risk-reward ratio."""
        risk = entry_price - initial_sl
        
        # Calculate risk-reward based targets
        max_rr = 3.0  # Maximum risk-reward ratio we aim for
        
        # First target at 50% of max RR
        tp1 = entry_price + (risk * (max_rr * 0.5))
        
        # Second target at full max RR
        tp2 = entry_price + (risk * max_rr)
        
        return initial_sl, tp1, tp2

    def detect_market_structure_shift(self, df: pd.DataFrame, lookback: int = 20) -> bool:
        """Detect Market Structure Shift (MSS) based on ICT concepts."""
        if len(df) < lookback:
            return False
            
        subset = df.iloc[-lookback:]
        
        # Find swing points
        highs = []
        lows = []
        
        for i in range(2, len(subset) - 2):
            # Higher high
            if subset['high'].iloc[i] > subset['high'].iloc[i-1] and subset['high'].iloc[i] > subset['high'].iloc[i-2] and \
               subset['high'].iloc[i] > subset['high'].iloc[i+1] and subset['high'].iloc[i] > subset['high'].iloc[i+2]:
                highs.append((i, subset['high'].iloc[i]))
                
            # Lower low
            if subset['low'].iloc[i] < subset['low'].iloc[i-1] and subset['low'].iloc[i] < subset['low'].iloc[i-2] and \
               subset['low'].iloc[i] < subset['low'].iloc[i+1] and subset['low'].iloc[i] < subset['low'].iloc[i+2]:
                lows.append((i, subset['low'].iloc[i]))
        
        # Check for higher lows (bullish MSS)
        if len(lows) >= 2 and lows[-1][1] > lows[-2][1]:
            return True
            
        return False

    async def scan_single_stock(self, symbol: str, start_date: datetime, end_date: datetime, 
                          duration: str = '365 D') -> List[Dict]:
        """Scan a single stock for trading setups with enhanced debugging."""
        try:
            # Ensure duration has proper format
            if ' ' not in duration and any(c.isalpha() for c in duration):
                for i, char in enumerate(duration):
                    if char.isalpha():
                        duration = duration[:i] + ' ' + duration[i:]
                        break
            
            # Get historical data
            hourly_df = await self.get_historical_data(symbol, end_date, duration, '1 hour')
            daily_df = await self.get_historical_data(symbol, end_date, duration, '1 day')
            
            # Check if we have enough data
            if not all([hourly_df is not None, daily_df is not None, 
                    len(hourly_df) >= 15, len(daily_df) >= 20]):
                logger.warning(f"Insufficient data for {symbol}")
                return []

            # Debugging counters
            total_candles = len(hourly_df) - 14  # Exclude first 14 candles used for indicators
            fvg_count = 0
            unmitigated_count = 0
            rejection_count = 0
            rr_count = 0
            valid_setups = 0
            trend_rejected = 0
            
            setups = []
            # Scan each hourly candle
            for idx in range(14, len(hourly_df)):
                time = hourly_df.index[idx]
                
                # Skip if outside our date range
                if not (start_date <= time <= end_date):
                    continue

                # Get data up to current candle
                data = hourly_df.iloc[:idx + 1]
                
                # Check market trend and regime
                trend, regime = self.get_trend_direction(daily_df, time)
                # Accept both up trends and neutral trends
                if trend == 'down':  # Only exclude downtrends
                    trend_rejected += 1
                    continue

                # Find FVGs
                fvgs = self.find_fvg(data, idx)
                if not fvgs:
                    continue
                
                fvg_count += 1
                fvg = fvgs[-1]  # Use the most recent FVG
                
                # Check if FVG is unmitigated
                if not self.is_unmitigated(data, fvg, idx):
                    continue
                
                unmitigated_count += 1
                
                if not self.is_unmitigated(data, fvg, idx):
                    continue

                unmitigated_count += 1

                # Check for confirmation signals - need at least 2 confirmations
                confirmation_count = 0

                # Check for rejection candle
                if self.has_rejection_candle(data, fvg, idx):
                    confirmation_count += 1
                    rejection_count += 1

                # Check for closing into FVG without penetration
                if self.has_closing_into_fvg(data, fvg, idx):
                    confirmation_count += 1

                # Check for volume confirmation
                if self.has_volume_confirmation(data, idx):
                    confirmation_count += 1

                # Check for moving average alignment
                if self.has_ma_alignment(data, idx):
                    confirmation_count += 1

                # Check for RSI confirmation
                if self.has_rsi_confirmation(data, idx):
                    confirmation_count += 1

                # Check for higher timeframe alignment
                setup_direction = 'bullish' if data['close'].iloc[idx] > data['open'].iloc[idx] else 'bearish'
                if self.has_higher_timeframe_alignment(symbol, time, setup_direction):
                    confirmation_count += 1

                # Require at least 2 confirmation signals
                if confirmation_count < 2:
                    continue

                # Setup entry parameters
                entry = data['close'].iloc[idx]
                sl = data['low'].iloc[idx]
                atr = data['atr'].iloc[idx]
                
                # Calculate targets
                initial_sl, tp1, tp2 = self.calculate_targets_and_trailing_sl(entry, sl, atr)
                
                # Calculate risk-reward ratio
                rr = (tp1 - entry) / (entry - sl) if entry > sl else 0
                
                # Add setup if risk-reward is acceptable
                if rr >= 1.5:  # Minimum risk-reward ratio
                    rr_count += 1
                    valid_setups += 1
                    setup = {
                        'symbol': symbol,
                        'time': time,
                        'entry': entry,
                        'stop_loss': sl,
                        'target1': tp1,
                        'target2': tp2,
                        'atr': atr,
                        'risk_reward': rr,
                        'trend': trend,
                        'regime': regime,
                        'setup_type': 'FVG_Rejection'
                    }
                    setups.append(setup)
            
            # Log detailed statistics
            logger.info(f"{symbol} scan statistics: Total candles: {total_candles}, "
                    f"FVGs found: {fvg_count}, Unmitigated: {unmitigated_count}, "
                    f"Rejection candles: {rejection_count}, Good RR: {rr_count}, "
                    f"Trend rejected: {trend_rejected}, Valid setups: {valid_setups}")
            
            logger.info(f"Found {len(setups)} setups for {symbol}")
            return setups
            
        except Exception as e:
            logger.error(f"Error scanning {symbol}: {e}")
            return []

    async def scan_stocks(self, symbols: List[str], start_date: datetime, end_date: datetime) -> Dict[str, List[Dict]]:
        """Scan multiple stocks for trading setups."""
        all_setups = {}
        
        for symbol in symbols:
            logger.info(f"Scanning {symbol}...")
            setups = await self.scan_single_stock(symbol, start_date, end_date)
            if setups:
                all_setups[symbol] = setups
                
        return all_setups

class BacktestEngine:
    """Backtests trading strategies using historical data."""
    
    def __init__(self, scanner: MarketScanner, initial_capital: float = 100000.0):
        self.scanner = scanner
        self.initial_capital = initial_capital
        self.current_capital = initial_capital
        self.positions = {}  # symbol -> {entry_price, shares, entry_date, stop_loss, target1, target2}
        self.closed_trades = []
        self.equity_curve = []
        self.max_risk_per_trade = 0.3  # 30% risk per trade
        self.max_portfolio_risk = 0.05  # 5% total portfolio risk
        self.fee_per_share = 0.0035  # $0.0035 per share
        self.slippage_percent = 0.002  # 0.2% slippage
        self.max_holding_period = 60  # Maximum days to hold a position
        
    def calculate_position_size(self, entry: float, stop_loss: float) -> int:
        """Calculate position size based on risk parameters."""
        if entry <= stop_loss:
            return 0
            
        risk_per_share = entry - stop_loss
        if risk_per_share <= 0:
            return 0
            
        # Calculate dollar risk - REDUCE MAX RISK PER TRADE
        dollar_risk = self.current_capital * self.max_risk_per_trade * 0.75  # Reduced by 25%
        
        # Calculate shares based on risk
        shares = int(dollar_risk / risk_per_share)
        
        # Add maximum position size as percentage of capital
        max_position_value = self.current_capital * 0.15  # Max 15% in any position
        shares = min(shares, int(max_position_value / entry))
        
        # Ensure we don't exceed maximum portfolio risk
        total_portfolio_risk = sum(
            self.positions[sym]['shares'] * (self.positions[sym]['entry_price'] - self.positions[sym]['stop_loss'])
            for sym in self.positions
        )
        max_dollar_risk = self.current_capital * self.max_portfolio_risk
        
        if total_portfolio_risk + (shares * risk_per_share) > max_dollar_risk:
            # Adjust shares to stay within portfolio risk limit
            remaining_risk = max_dollar_risk - total_portfolio_risk
            if remaining_risk <= 0:
                return 0
            shares = min(shares, int(remaining_risk / risk_per_share))
        
        return max(1, shares)  # At least 1 share

    def apply_slippage_and_fees(self, price: float, shares: int, is_buy: bool) -> float:
        """Apply slippage and fees to a transaction."""
        # Apply slippage (worse price for buys, better for sells)
        slippage_adjustment = price * self.slippage_percent
        adjusted_price = price + slippage_adjustment if is_buy else price - slippage_adjustment
        
        # Apply fees
        fees = shares * self.fee_per_share
        
        # Return total cost including fees
        transaction_value = shares * adjusted_price
        return transaction_value + fees if is_buy else transaction_value - fees

    def backtest(self, setups: Dict[str, List[Dict]], start_date: datetime, end_date: datetime) -> Dict:
        """Run backtest on the given setups."""
        # Sort all setups by date
        all_setups_sorted = []
        for symbol, symbol_setups in setups.items():
            for setup in symbol_setups:
                setup['symbol'] = symbol
                all_setups_sorted.append(setup)
        
        all_setups_sorted.sort(key=lambda x: x['time'])
        
        # Reset backtest state
        self.current_capital = self.initial_capital
        self.positions = {}
        self.closed_trades = []
        self.equity_curve = [{'date': start_date, 'equity': self.initial_capital}]
        
        # Process each setup chronologically
        for setup in all_setups_sorted:
            setup_time = setup['time']
            
            # Skip setups outside our date range
            if setup_time < start_date or setup_time > end_date:
                continue
                
            # Process existing positions first (check for exits)
            self._process_positions(setup_time, end_date)
            
            # Skip entry if we already have a position in this symbol
            if setup['symbol'] in self.positions:
                continue
                
            # Calculate position size
            shares = self.calculate_position_size(setup['entry'], setup['stop_loss'])
            
            if shares <= 0:
                continue
                
            # Apply slippage and fees to entry
            actual_cost = self.apply_slippage_and_fees(setup['entry'], shares, True)
            
            # Check if we have enough capital
            if actual_cost > self.current_capital:
                # Adjust shares to available capital
                shares = int((self.current_capital / actual_cost) * shares)
                if shares <= 0:
                    continue
                actual_cost = self.apply_slippage_and_fees(setup['entry'], shares, True)
            
            # Enter position
            self.positions[setup['symbol']] = {
                'entry_price': setup['entry'],
                'shares': shares,
                'entry_date': setup_time,
                'stop_loss': setup['stop_loss'],
                'target1': setup['target1'],
                'target2': setup['target2'],
                'max_holding_date': setup_time + timedelta(days=self.max_holding_period)
            }
            
            # Update capital
            self.current_capital -= actual_cost
            
            # Update equity curve
            self.equity_curve.append({
                'date': setup_time,
                'equity': self._calculate_total_equity(setup_time)
            })
        
        # Close any remaining positions at the end of the backtest
        self._close_all_positions(end_date)
        
        # Calculate performance metrics
        return self._calculate_performance_metrics()

    def _process_positions(self, current_time: datetime, end_date: datetime) -> None:
        """Process existing positions for potential exits."""
        symbols_to_remove = []
        
        for symbol, position in self.positions.items():
            # Get historical data to check exit conditions
            try:
                # Use 5-minute data for more precise exit timing
                data = asyncio.run(self.scanner.get_5min_data(
                    symbol, 
                    position['entry_date'], 
                    min(current_time, end_date)
                ))
                
                if data is None or data.empty:
                    continue
                    
                # Check for stop loss hit
                if any(data['low'] <= position['stop_loss']):
                    # Find the first bar where stop loss was hit
                    stop_hit_bars = data[data['low'] <= position['stop_loss']]
                    exit_time = stop_hit_bars.index[0]
                    exit_price = position['stop_loss']
                    
                    self._close_position(symbol, exit_price, exit_time, 'Stop Loss')
                    symbols_to_remove.append(symbol)
                    continue
                
                # Check for first target hit - close 50% of position
                if not position.get('partial_exit', False) and any(data['high'] >= position['target1']):
                    # Find the first bar where target was hit
                    target_hit_bars = data[data['high'] >= position['target1']]
                    exit_time = target_hit_bars.index[0]
                    exit_price = position['target1']
                    
                    # Calculate shares to close (50% of position)
                    shares_to_close = position['shares'] // 2
                    if shares_to_close > 0:
                        # Close partial position
                        self._close_partial_position(symbol, exit_price, exit_time, shares_to_close, 'Partial TP')
                        
                        # Mark position as partially exited
                        position['partial_exit'] = True
                        position['shares'] -= shares_to_close
                        
                        # Move stop loss to breakeven
                        position['stop_loss'] = position['entry_price']
                        
                        # If all shares were closed (odd number of shares case)
                        if position['shares'] <= 0:
                            symbols_to_remove.append(symbol)
                            continue
                
                # Check for second target hit for remaining position
                if position.get('partial_exit', False) and any(data['high'] >= position['target2']):
                    # Find the first bar where target was hit
                    target_hit_bars = data[data['high'] >= position['target2']]
                    exit_time = target_hit_bars.index[0]
                    exit_price = position['target2']
                    
                    self._close_position(symbol, exit_price, exit_time, 'Final TP')
                    symbols_to_remove.append(symbol)
                    continue
                
                # Add trailing stop logic
                if len(data) > 5:  # Need some bars to establish trailing stop
                    # Calculate trailing stop based on ATR
                    atr = data['atr'].iloc[-1] if 'atr' in data.columns else position['entry_price'] * 0.02
                    highest_high = data['high'].max()
                    
                    # More aggressive trailing stop after partial exit
                    if position.get('partial_exit', False):
                        trailing_stop = max(position['stop_loss'], highest_high - 1.5 * atr)
                    else:
                        trailing_stop = max(position['stop_loss'], highest_high - 2 * atr)
                    
                    # Exit if price falls below trailing stop
                    if data['close'].iloc[-1] < trailing_stop and highest_high > position['entry_price'] * 1.05:
                        exit_price = data['close'].iloc[-1]
                        exit_time = data.index[-1]
                        self._close_position(symbol, exit_price, exit_time, 'Trailing Stop')
                        symbols_to_remove.append(symbol)
                        continue
                
                # Check for max holding period (60 days)
                if current_time >= position['entry_date'] + timedelta(days=60):
                    # Use the close of the last bar as exit price
                    exit_price = data['close'].iloc[-1]
                    exit_time = data.index[-1]
                    
                    self._close_position(symbol, exit_price, exit_time, 'Time Exit')
                    symbols_to_remove.append(symbol)
                    continue
                
            except Exception as e:
                logger.error(f"Error processing position for {symbol}: {e}")
        
        # Remove closed positions
        for symbol in symbols_to_remove:
            if symbol in self.positions:
                del self.positions[symbol]

    def _close_position(self, symbol: str, exit_price: float, exit_time: datetime, exit_reason: str) -> None:
        """Close a position and record the trade."""
        position = self.positions[symbol]
        
        # Apply slippage and fees to exit
        actual_proceeds = self.apply_slippage_and_fees(exit_price, position['shares'], False)
        
        # Calculate P&L
        entry_value = position['entry_price'] * position['shares']
        exit_value = exit_price * position['shares']
        pnl = exit_value - entry_value
        pnl_percent = (exit_price / position['entry_price'] - 1) * 100
        
        # Record the trade
        trade = {
            'symbol': symbol,
            'entry_date': position['entry_date'],
            'exit_date': exit_time,
            'entry_price': position['entry_price'],
            'exit_price': exit_price,
            'shares': position['shares'],
            'pnl': pnl,
            'pnl_percent': pnl_percent,
            'exit_reason': exit_reason
        }
        self.closed_trades.append(trade)
        
        # Update capital
        self.current_capital += actual_proceeds
        
        # Update equity curve
        self.equity_curve.append({
            'date': exit_time,
            'equity': self._calculate_total_equity(exit_time)
        })

    def _close_all_positions(self, exit_date: datetime) -> None:
        """Close all remaining positions at the end of the backtest."""
        symbols = list(self.positions.keys())
        
        for symbol in symbols:
            try:
                # Get the latest price data up to exit_date
                data = asyncio.run(self.scanner.get_historical_data(
                    symbol, exit_date, '1 D', '1 hour'
                ))
                
                if data is None or data.empty:
                    continue
                
                # Use the last available close price
                exit_price = data['close'].iloc[-1]
                exit_time = data.index[-1]
                
                self._close_position(symbol, exit_price, exit_time, 'End of Backtest')
                
            except Exception as e:
                logger.error(f"Error closing position for {symbol}: {e}")
        
        # Clear positions
        self.positions = {}

    def _close_partial_position(self, symbol: str, exit_price: float, exit_time: datetime, shares: int, exit_reason: str) -> None:
        """Close part of a position and record the partial trade."""
        position = self.positions[symbol]
        
        # Apply slippage and fees to exit
        actual_proceeds = self.apply_slippage_and_fees(exit_price, shares, False)
        
        # Calculate P&L for the closed portion
        entry_value = position['entry_price'] * shares
        exit_value = exit_price * shares
        pnl = exit_value - entry_value
        pnl_percent = (exit_price / position['entry_price'] - 1) * 100
        
        # Record the partial trade
        trade = {
            'symbol': symbol,
            'entry_date': position['entry_date'],
            'exit_date': exit_time,
            'entry_price': position['entry_price'],
            'exit_price': exit_price,
            'shares': shares,
            'pnl': pnl,
            'pnl_percent': pnl_percent,
            'exit_reason': exit_reason
        }
        self.closed_trades.append(trade)
        
        # Update capital
        self.current_capital += actual_proceeds
        
        # Update equity curve
        self.equity_curve.append({
            'date': exit_time,
            'equity': self._calculate_total_equity(exit_time)
        })
    
    def _calculate_total_equity(self, current_time: datetime) -> float:
        """Calculate total equity including open positions."""
        # Start with cash
        total_equity = self.current_capital
        
        # Add value of open positions
        for symbol, position in self.positions.items():
            try:
                # Get latest price
                data = asyncio.run(self.scanner.get_historical_data(
                    symbol, current_time, '1 D', '1 hour'
                ))
                
                if data is None or data.empty:
                    # Use entry price if no data available
                    current_price = position['entry_price']
                else:
                    # Use the last available close price
                    current_price = data['close'].iloc[-1]
                
                position_value = current_price * position['shares']
                total_equity += position_value
                
            except Exception as e:
                logger.error(f"Error calculating equity for {symbol}: {e}")
                # Use entry price as fallback
                position_value = position['entry_price'] * position['shares']
                total_equity += position_value
        
        return total_equity

    def _calculate_performance_metrics(self) -> Dict:
        """Calculate performance metrics for the backtest."""
        if not self.closed_trades:
            return {
                'initial_capital': self.initial_capital,
                'final_capital': self.current_capital,
                'total_return_pct': 0,
                'win_rate': 0,
                'profit_factor': 0,
                'max_drawdown_pct': 0,
                'total_trades': 0,
                'equity_curve': self.equity_curve,
                'trades': []
            }
        
        # Calculate basic metrics
        initial_capital = self.initial_capital
        final_capital = self.current_capital
        total_return_pct = (final_capital / initial_capital - 1) * 100
        
        # Win rate
        winning_trades = [t for t in self.closed_trades if t['pnl'] > 0]
        win_rate = len(winning_trades) / len(self.closed_trades) if self.closed_trades else 0
        
        # Profit factor
        gross_profit = sum(t['pnl'] for t in self.closed_trades if t['pnl'] > 0)
        gross_loss = abs(sum(t['pnl'] for t in self.closed_trades if t['pnl'] < 0))
        profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')
        
        # Maximum drawdown
        equity_values = [point['equity'] for point in self.equity_curve]
        max_drawdown_pct = self._calculate_max_drawdown(equity_values)
        
        # Format trades for output
        trades_output = []
        for trade in self.closed_trades:
            trades_output.append({
                'symbol': trade['symbol'],
                'entry_date': trade['entry_date'],
                'exit_date': trade['exit_date'],
                'entry_price': trade['entry_price'],
                'exit_price': trade['exit_price'],
                'shares': trade['shares'],
                'pnl': trade['pnl'],
                'pnl_percent': trade['pnl_percent'],
                'exit_reason': trade['exit_reason']
            })
        
        return {
            'initial_capital': initial_capital,
            'final_capital': final_capital,
            'total_return_pct': total_return_pct,
            'win_rate': win_rate,
            'profit_factor': profit_factor,
            'max_drawdown_pct': max_drawdown_pct,
            'total_trades': len(self.closed_trades),
            'equity_curve': self.equity_curve,
            'trades': trades_output
        }

    def _calculate_max_drawdown(self, equity_curve: List[float]) -> float:
        """Calculate maximum drawdown percentage."""
        if not equity_curve:
            return 0
            
        max_drawdown = 0
        peak = equity_curve[0]
        
        for equity in equity_curve:
            if equity > peak:
                peak = equity
            else:
                drawdown = (peak - equity) / peak
                max_drawdown = max(max_drawdown, drawdown)
        
        return max_drawdown * 100  # Convert to percentage

    def generate_report(self, results: Dict, output_dir: str = './reports') -> None:
        """Generate performance reports and charts."""
        import matplotlib.pyplot as plt
        import matplotlib.dates as mdates
        from matplotlib.ticker import FuncFormatter
        
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. Create improved equity curve chart
        plt.figure(figsize=(12, 6))
        dates = [point['date'] for point in results['equity_curve']]
        equity = [point['equity'] for point in results['equity_curve']]
        
        # Sort the data by date to ensure proper ordering
        sorted_data = sorted(zip(dates, equity), key=lambda x: x[0])
        dates = [item[0] for item in sorted_data]
        equity = [item[1] for item in sorted_data]
        
        # Plot with improved styling
        plt.plot(dates, equity, linewidth=2, color='#0079a3', alpha=0.9)
        
        # Add markers at trade points for better visibility
        trade_dates = [trade['entry_date'] for trade in results['trades']]
        trade_exits = [trade['exit_date'] for trade in results['trades']]
        
        # Get equity values at trade dates
        trade_entries_equity = []
        trade_exits_equity = []
        
        for trade_date in trade_dates:
            # Find closest equity point
            closest_idx = min(range(len(dates)), key=lambda i: abs(dates[i] - trade_date))
            trade_entries_equity.append(equity[closest_idx])
        
        for exit_date in trade_exits:
            # Find closest equity point
            closest_idx = min(range(len(dates)), key=lambda i: abs(dates[i] - exit_date))
            trade_exits_equity.append(equity[closest_idx])
        
        # Plot entry and exit points
        plt.scatter(trade_dates, trade_entries_equity, color='green', s=50, alpha=0.7, label='Entry')
        plt.scatter(trade_exits, trade_exits_equity, color='red', s=50, alpha=0.7, label='Exit')
        
        # Add grid and styling
        plt.title('Equity Curve', fontsize=16)
        plt.xlabel('Date', fontsize=12)
        plt.ylabel('Equity ($)', fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        # Format axes
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'${x:,.2f}'))
        
        # Add horizontal line for initial capital
        plt.axhline(y=results['initial_capital'], color='gray', linestyle='--', alpha=0.5, 
                    label=f'Initial Capital (${results["initial_capital"]:,.2f})')
        
        # Set y-axis limits with some padding
        min_equity = min(equity) * 0.95
        max_equity = max(equity) * 1.05
        plt.ylim(min_equity, max_equity)
        
        # Improve x-axis display
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        # Save the figure with high DPI for better quality
        plt.savefig(os.path.join(output_dir, 'equity_curve.png'), dpi=300)
        plt.close()
        
        # Continue with the rest of the report generation...
        # 2. Create P&L distribution
        if results['trades']:
            plt.figure(figsize=(12, 6))
            pnl_pcts = [trade['pnl_percent'] for trade in results['trades']]
            plt.hist(pnl_pcts, bins=20, alpha=0.7, color='#0079a3')
            plt.axvline(0, color='red', linestyle='--')
            plt.title('P&L Distribution', fontsize=16)
            plt.xlabel('P&L %', fontsize=12)
            plt.ylabel('Frequency', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'pnl_distribution.png'), dpi=300)
            plt.close()
        
        # 4. Save trade log to CSV
        if results['trades']:
            trades_df = pd.DataFrame(results['trades'])
            trades_df.to_csv(os.path.join(output_dir, 'trade_log.csv'), index=False)
            
        # Print summary to console
        print("===== BACKTEST RESULTS =====")
        print(f"Initial Capital: ${results['initial_capital']:.2f}")
        print(f"Final Capital: ${results['final_capital']:.2f}")
        print(f"Total Return: {results['total_return_pct']:.2f}%")
        print(f"Win Rate: {results['win_rate']*100:.2f}%")
        print(f"Profit Factor: {results['profit_factor']:.2f}")
        print(f"Max Drawdown: {results['max_drawdown_pct']:.2f}%")
        print(f"Total Trades: {results['total_trades']}")
        print(f"Report files generated: equity_curve.png, pnl_distribution.png, monthly_returns.png, trade_log.csv")
        
        return os.path.join(output_dir, 'trade_log.csv')

async def main():
    # Define symbols to scan
    symbols = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'NVDA', 'TSLA', 'AMD']
    
    # Define date range for backtest
    start_date = datetime(2023, 1, 1, tzinfo=UTC)
    end_date = datetime(2023, 12, 31, tzinfo=UTC)
    
    # Initialize scanner and connect to IB
    scanner = MarketScanner()
    connected = await scanner.connect()
    
    if not connected:
        logger.error("Failed to connect to Interactive Brokers. Exiting.")
        return
    
    try:
        # Scan for setups
        setups = await scanner.scan_stocks(symbols, start_date, end_date)
        
        # Initialize backtest engine
        backtest = BacktestEngine(scanner)
        
        # Run backtest with defined date range
        results = backtest.backtest(setups, start_date, end_date)
        
        # Generate reports
        backtest.generate_report(results)
        
        # Print trade details
        if results['trades']:
            print("\nSymbol,Entry Date,Exit Date,Entry Price,Exit Price,Shares,P&L,P&L %")
            for trade in results['trades']:
                print(f"{trade['symbol']},{trade['entry_date']},{trade['exit_date']},{trade['entry_price']:.2f},{trade['exit_price']:.2f},{trade['shares']},{trade['pnl']:.2f},{trade['pnl_percent']:.2f}")
        
    except Exception as e:
        logger.error(f"Error in main execution: {e}")
    finally:
        # Disconnect from IB
        scanner.disconnect()

if __name__ == "__main__":
    asyncio.run(main())
