import os
import pickle
from datetime import datetime, timedelta
import asyncio
import nest_asyncio
from pytz import UTC
import logging
from logging.handlers import RotatingFileHandler
from ib_insync import IB, Stock, util
import pandas as pd
import numpy as np
from typing import Optional, List, Dict, Tuple, Any

# Configure logging
log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
log_file = 'trading_system.log'
log_handler = RotatingFileHandler(log_file, maxBytes=5*1024*1024, backupCount=3)
log_handler.setFormatter(log_formatter)

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(log_handler)
console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)
logger.addHandler(console_handler)
nest_asyncio.apply()

class DataCache:
    """Handles caching of historical market data to reduce API calls."""
    
    def __init__(self, cache_dir: str = './cache'):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

    def get_cache_path(self, symbol: str, timeframe: str) -> str:
        return os.path.join(self.cache_dir, f'{symbol}_{timeframe}.pickle')

    def is_cached(self, symbol: str, timeframe: str) -> bool:
        cache_path = self.get_cache_path(symbol, timeframe)
        return os.path.exists(cache_path)

    def load_cache(self, symbol: str, timeframe: str) -> pd.DataFrame:
        try:
            with open(self.get_cache_path(symbol, timeframe), 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            logger.error(f"Error loading cache for {symbol}_{timeframe}: {e}")
            return pd.DataFrame()

    def save_cache(self, symbol: str, timeframe: str, data: pd.DataFrame) -> None:
        try:
            with open(self.get_cache_path(symbol, timeframe), 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            logger.error(f"Error saving cache for {symbol}_{timeframe}: {e}")


class MarketScanner:
    """Scans the market for trading setups based on fair value gaps (FVG)."""
    
    def __init__(self, host: str = '127.0.0.1', port: int = 7497, client_id: int = 1):
        self.ib = IB()
        self.host = host
        self.port = port
        self.client_id = client_id
        self.fee_per_share = 0.0035
        self.max_slippage_percent = 0.02
        self.cache = DataCache()
        self._connected = False

    async def connect(self, retries: int = 3) -> bool:
        """Connect to Interactive Brokers TWS or Gateway."""
        for attempt in range(retries):
            try:
                if not self.ib.isConnected():
                    await self.ib.connectAsync(self.host, self.port, clientId=self.client_id)
                    self._connected = True
                    logger.info(f"Connected to Interactive Brokers at {self.host}:{self.port}")
                    return True
                else:
                    self._connected = True
                    logger.info("Already connected to Interactive Brokers")
                    return True
            except Exception as e:
                logger.error(f"Connection attempt {attempt + 1} failed: {e}")
                if attempt < retries - 1:
                    await asyncio.sleep(2)
        
        logger.error("Failed to connect after retries")
        self._connected = False
        return False

    def disconnect(self) -> None:
        """Disconnect from Interactive Brokers TWS or Gateway."""
        try:
            if self.ib.isConnected():
                self.ib.disconnect()
                logger.info("Disconnected from Interactive Brokers")
            self._connected = False
        except Exception as e:
            logger.error(f"Disconnect failed: {e}")
            self._connected = False

    async def get_historical_data(self, symbol: str, end_date: datetime, 
                                 duration: str, bar_size: str) -> Optional[pd.DataFrame]:
        """Fetch historical data for a symbol with technical indicators."""
        # Check cache first
        if self.cache.is_cached(symbol, bar_size):
            df = self.cache.load_cache(symbol, bar_size)
            if not df.empty:
                return df

        try:
            contract = Stock(symbol, 'SMART', 'USD')
            
            # Ensure duration is in the correct format: integer{SPACE}unit
            if duration[0].isdigit() and ' ' not in duration:
                # Find the position where digits end
                for i, char in enumerate(duration):
                    if not char.isdigit():
                        # Insert a space between number and unit
                        duration = duration[:i] + ' ' + duration[i:]
                        break
            
            bars = await self.ib.reqHistoricalDataAsync(
                contract, end_date, duration, bar_size, 'TRADES', useRTH=True
            )
            
            if not bars:
                logger.warning(f"No historical data available for {symbol}")
                return None

            # Convert to DataFrame and process
            df = util.df(bars)
            df['date'] = pd.to_datetime(df['date'], utc=True, errors='coerce')
            
            if df['date'].isna().any():
                logger.error(f"Date parsing failed for {symbol}")
                return None
                
            df.set_index('date', inplace=True)
            
            # Calculate ATR
            df['atr'] = self._calculate_atr(df)
            
            # Add additional indicators for daily timeframe
            if bar_size == '1 day':
                self._add_daily_indicators(df)

            # Cache the data
            self.cache.save_cache(symbol, bar_size, df)
            return df
            
        except Exception as e:
            logger.error(f"Failed to fetch historical data for {symbol}: {e}")
            return None

    def _calculate_atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average True Range."""
        # Calculate true range components
        high_low = df['high'] - df['low']
        high_close_prev = abs(df['high'] - df['close'].shift(1))
        low_close_prev = abs(df['low'] - df['close'].shift(1))
        
        # Combine components to get true range
        # Use pandas max method instead of numpy.maximum.reduce
        true_range = pd.DataFrame({
            'hl': high_low,
            'hcp': high_close_prev,
            'lcp': low_close_prev
        }).max(axis=1)
        
        # Apply rolling mean to the pandas Series
        return true_range.rolling(window=period, min_periods=1).mean()

    def _add_daily_indicators(self, df: pd.DataFrame) -> None:
        """Add technical indicators to daily data."""
        # Simple Moving Average and its slope
        df['sma_20'] = df['close'].rolling(window=20, min_periods=1).mean()
        df['sma_slope'] = df['sma_20'].diff()
        
        # Directional Movement Index components
        df['plus_di'] = 100 * (df['high'].diff().clip(lower=0) / df['atr']).rolling(14, min_periods=1).mean()
        df['minus_di'] = 100 * ((-df['low'].diff().clip(upper=0)) / df['atr']).rolling(14, min_periods=1).mean()
        
        # Average Directional Index
        df['adx'] = 100 * abs(df['plus_di'] - df['minus_di']) / (df['plus_di'] + df['minus_di']).replace(0, np.nan).rolling(14, min_periods=1).mean()
        
        # Bollinger Band Width
        std_20 = df['close'].rolling(20, min_periods=1).std()
        df['bb_width'] = (df['sma_20'] + 2 * std_20 - (df['sma_20'] - 2 * std_20)) / df['sma_20']

    async def get_5min_data(self, symbol: str, start_time: datetime, end_date: datetime) -> Optional[pd.DataFrame]:
        """Get 5-minute bar data for a symbol."""
        if self.cache.is_cached(symbol, '5min'):
            df = self.cache.load_cache(symbol, '5min')
            if not df.empty and any(df.index >= start_time):
                return df[df.index >= start_time]

        # Use a standard duration format instead of bars
        # Calculate days between dates and add some buffer
        days_diff = (end_date - start_time).days + 1
        duration = f"{max(days_diff, 7)} D"  # At least 7 days
        
        df = await self.get_historical_data(symbol, end_date, duration, '5 mins')
        return df[df.index >= start_time] if df is not None and not df.empty else None

    def find_fvg(self, df: pd.DataFrame, current_index: int) -> List[Tuple[Any, float, float]]:
        """Find Fair Value Gaps in the data."""
        fvgs = []
        for i in range(2, current_index + 1):
            # Bullish FVG: Current candle's low is higher than previous-1 candle's high
            if (df['close'].iloc[i-1] > df['open'].iloc[i-1] and  # Previous candle is bullish
                df['low'].iloc[i] > df['high'].iloc[i-2]):        # Gap between i-2 and i
                fvgs.append((df.index[i-1], df['high'].iloc[i-2], df['low'].iloc[i]))
        return fvgs

    def is_unmitigated(self, df: pd.DataFrame, fvg: Tuple[Any, float, float], current_index: int) -> bool:
        """Check if a Fair Value Gap has not been mitigated."""
        subset = df.loc[fvg[0]:df.index[current_index]]
        # FVG is mitigated if price has traded through the gap
        return not ((subset['low'] <= fvg[1]) & (subset['high'] >= fvg[2])).any()

    def has_rejection_candle(self, df: pd.DataFrame, fvg: Tuple[Any, float, float], current_index: int) -> bool:
        """Enhanced rejection candle detection with volume confirmation."""
        candle = df.iloc[current_index]
        prev_candle = df.iloc[current_index-1] if current_index > 0 else None
        
        # Check for bullish rejection with volume confirmation
        rejection_pattern = (
            fvg[1] <= candle['close'] <= fvg[2] and  # Close within FVG
            candle['close'] > candle['open'] and      # Bullish candle
            (candle['low'] < fvg[1] or candle['open'] < fvg[1]) and  # Tested below FVG
            candle['high'] - candle['close'] < 0.3 * (candle['high'] - candle['low'])  # Strong close
        )
        
        # Add volume confirmation if available
        volume_confirmation = True
        if 'volume' in df.columns and prev_candle is not None:
            volume_confirmation = candle['volume'] > prev_candle['volume']
            
        return rejection_pattern and volume_confirmation

    def has_bos(self, df: pd.DataFrame, current_index: int, lookback: int = 10) -> bool:
        """Check if there's a breakout of structure in recent candles."""
        start_idx = max(1, current_index - lookback)
        for i in range(start_idx, current_index):
            if df['close'].iloc[i] > df['high'].iloc[i-1]:
                return True
        return False

    def get_trend_direction(self, daily_df: pd.DataFrame, current_date: datetime) -> Tuple[str, str]:
        """Determine market trend and regime with relaxed conditions."""
        subset = daily_df[daily_df.index <= current_date]
        if len(subset) < 20:
            return 'neutral', 'unknown'
        
        # Relaxed trend determination
        trend = 'neutral'
        # Lower ADX threshold from 25 to 20
        if (subset['sma_slope'].iloc[-1] > 0 and 
            subset['adx'].iloc[-1] > 20 and 
            subset['close'].iloc[-1] > subset['sma_20'].iloc[-1]):  # Changed from previous high comparison
            trend = 'up'
        elif (subset['sma_slope'].iloc[-1] < 0 and 
              subset['adx'].iloc[-1] > 20 and 
              subset['close'].iloc[-1] < subset['sma_20'].iloc[-1]):  # Changed from previous low comparison
            trend = 'down'
        
        # Accept both trending and ranging regimes
        regime = 'trending' if subset['bb_width'].iloc[-1] > subset['bb_width'].quantile(0.5) else 'ranging'
        
        return trend, regime

    def is_potential_trend(self, df: pd.DataFrame) -> bool:
        """Alternative trend detection with relaxed conditions."""
        # Check if price is above 20-day SMA
        above_sma = df['close'].iloc[-1] > df['sma_20'].iloc[-1]
        
        # Check if 20-day SMA is higher than 50-day SMA (if available)
        sma_50 = df['close'].rolling(window=50, min_periods=1).mean().iloc[-1]
        sma_alignment = df['sma_20'].iloc[-1] > sma_50
        
        # Check for higher lows in recent price action
        recent_lows = df['low'].iloc[-10:].rolling(window=3).min()
        higher_lows = recent_lows.is_monotonic_increasing
        
        # Return true if at least 2 of 3 conditions are met
        conditions_met = sum([above_sma, sma_alignment, higher_lows])
        return conditions_met >= 2

    def calculate_targets_and_trailing_sl(self, entry_price: float, initial_sl: float, atr: float) -> Tuple[float, float, Optional[float]]:
        """Calculate initial profit targets based on ATR."""
        risk = entry_price - initial_sl
        tp1 = entry_price + 2 * atr
        tp2 = entry_price + 4 * atr
        return initial_sl, tp1, tp2

    def detect_market_structure_shift(self, df: pd.DataFrame, lookback: int = 20) -> bool:
        """Detect Market Structure Shift (MSS) based on ICT concepts."""
        if len(df) < lookback:
            return False
            
        subset = df.iloc[-lookback:]
        
        # Find swing points
        highs = []
        lows = []
        
        for i in range(2, len(subset) - 2):
            # Higher high
            if subset['high'].iloc[i] > subset['high'].iloc[i-1] and subset['high'].iloc[i] > subset['high'].iloc[i-2] and \
               subset['high'].iloc[i] > subset['high'].iloc[i+1] and subset['high'].iloc[i] > subset['high'].iloc[i+2]:
                highs.append((i, subset['high'].iloc[i]))
                
            # Lower low
            if subset['low'].iloc[i] < subset['low'].iloc[i-1] and subset['low'].iloc[i] < subset['low'].iloc[i-2] and \
               subset['low'].iloc[i] < subset['low'].iloc[i+1] and subset['low'].iloc[i] < subset['low'].iloc[i+2]:
                lows.append((i, subset['low'].iloc[i]))
        
        # Check for higher lows (bullish MSS)
        if len(lows) >= 2 and lows[-1][1] > lows[-2][1]:
            return True
            
        return False

    async def scan_single_stock(self, symbol: str, start_date: datetime, end_date: datetime, 
                              duration: str = '365 D') -> List[Dict]:
        """Scan a single stock for trading setups."""
        try:
            # Ensure duration has proper format
            if ' ' not in duration and any(c.isalpha() for c in duration):
                for i, char in enumerate(duration):
                    if char.isalpha():
                        duration = duration[:i] + ' ' + duration[i:]
                        break
            
            # Get historical data
            hourly_df = await self.get_historical_data(symbol, end_date, duration, '1 hour')
            daily_df = await self.get_historical_data(symbol, end_date, duration, '1 day')
            
            # Check if we have enough data
            if not all([hourly_df is not None, daily_df is not None, 
                      len(hourly_df) >= 15, len(daily_df) >= 20]):
                logger.warning(f"Insufficient data for {symbol}")
                return []

            setups = []
            # Scan each hourly candle
            for idx in range(14, len(hourly_df)):
                time = hourly_df.index[idx]
                
                # Skip if outside our date range
                if not (start_date <= time <= end_date):
                    continue

                # Get data up to current candle
                data = hourly_df.iloc[:idx + 1]
                
                # Check market trend and regime
                trend, regime = self.get_trend_direction(daily_df, time)
                # Accept both up trends and neutral trends
                if trend == 'down':  # Only exclude downtrends
                    continue

                # Find FVGs and check setup conditions
                fvgs = self.find_fvg(data, idx)
                if not fvgs:
                    continue
                    
                fvg = fvgs[-1]  # Use the most recent FVG
                
                # Check if FVG is valid for our setup
                if not self.is_unmitigated(data, fvg, idx) or \
                   not self.has_rejection_candle(data, fvg, idx):
                    # Removed the BOS check
                    continue

                # Setup entry parameters
                entry = data['close'].iloc[idx]
                sl = data['low'].iloc[idx]
                atr = data['atr'].iloc[idx]
                
                # Calculate targets - FIXED to avoid look-ahead bias
                initial_sl, tp1, tp2 = self.calculate_targets_and_trailing_sl(entry, sl, atr)
                
                                # Calculate risk-reward ratio
                rr = (tp1 - entry) / (entry - sl) if entry > sl else 0
                
                # Add setup if risk-reward is favorable
                if rr >= 1.5:  # Changed from 2 to 1.5
                    setups.append({
                        'symbol': symbol, 
                        'date': time, 
                        'entry': entry, 
                        'initial_sl': sl,
                        'trailing_sl': initial_sl, 
                        'target_1': tp1, 
                        'target_2': tp2, 
                        'rr_ratio': rr, 
                        'shares': 1.0,
                        'fvg_high': fvg[1],
                        'fvg_low': fvg[2]
                    })
                    
            return setups
            
        except Exception as e:
            logger.error(f"Error scanning {symbol}: {e}")
            return []

    async def scan_market(self, symbols: List[str], start_date: datetime, end_date: datetime, 
                    duration: str = '365 D') -> List[Dict]:
        """Scan multiple stocks for trading setups."""
        # Ensure duration has proper format
        if ' ' not in duration and any(c.isalpha() for c in duration):
            for i, char in enumerate(duration):
                if char.isalpha():
                    duration = duration[:i] + ' ' + duration[i:]
                    break
        
        # Connect to IB if not already connected
        if not self._connected:
            connected = await self.connect()
            if not connected:
                logger.error("Failed to connect to Interactive Brokers")
                return []
        
        all_setups = []
        for symbol in symbols:
            logger.info(f"Scanning {symbol}...")
            setups = await self.scan_single_stock(symbol, start_date, end_date, duration)
            if setups:
                logger.info(f"Found {len(setups)} setups for {symbol}")
                all_setups.extend(setups)
            
        # Sort setups by date
        all_setups.sort(key=lambda x: x['date'])
        
        # Apply SMC principles filtering
        filtered_setups = self.filter_by_smc_principles(all_setups)
        
        return filtered_setups
    
    def filter_by_smc_principles(self, setups: List[Dict]) -> List[Dict]:
        """Filter setups using Smart Money Concepts principles."""
        filtered_setups = []
        
        for setup in setups:
            # Calculate risk-reward ratio with more conservative targets
            entry = setup['entry']
            sl = setup['initial_sl']
            risk = entry - sl
            
            # Ensure minimum risk-reward of 1.5:1
            if risk <= 0 or setup['rr_ratio'] < 1.5:
                continue
                
            # Ensure FVG size is proportional to ATR
            fvg_size = setup['fvg_low'] - setup['fvg_high']
            if fvg_size < 0.3 * risk:  #**FVG should be at least half the risk**
                continue
                
            # Accept the setup if it passes all filters
            filtered_setups.append(setup)
            
        return filtered_setups
    
    def plot_fvg_setup(self, symbol: str, setup: Dict, hourly_df: pd.DataFrame):
        """Plot the 1-hour chart with FVG visualization."""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.dates as mdates
            from matplotlib.patches import Rectangle
            
            # Extract setup date and FVG levels
            setup_date = setup['date']
            fvg_high = setup['fvg_high']
            fvg_low = setup['fvg_low']
            
            # Get data for plotting (20 bars before and 10 bars after setup)
            start_idx = hourly_df.index.get_loc(setup_date, method='nearest') - 20
            end_idx = min(start_idx + 30, len(hourly_df) - 1)
            
            plot_df = hourly_df.iloc[max(0, start_idx):end_idx + 1].copy()
            
            # Create figure
            fig, ax = plt.subplots(figsize=(12, 8))
            
            # Plot candlesticks
            for i, (idx, row) in enumerate(plot_df.iterrows()):
                color = 'green' if row['close'] >= row['open'] else 'red'
                ax.plot([i, i], [row['low'], row['high']], color=color)
                rect = Rectangle((i-0.4, row['open']), 0.8, row['close']-row['open'], 
                                color=color, alpha=0.5)
                ax.add_patch(rect)
            
            # Add FVG rectangle
            fvg_idx = plot_df.index.get_loc(setup_date, method='nearest')
            ax.axhspan(fvg_high, fvg_low, alpha=0.2, color='blue', 
                      xmin=fvg_idx/len(plot_df), xmax=1.0)
            
            # Add entry, stop loss and targets
            ax.axhline(y=setup['entry'], color='green', linestyle='--', label=f"Entry: {setup['entry']:.2f}")
            ax.axhline(y=setup['initial_sl'], color='red', linestyle='--', label=f"SL: {setup['initial_sl']:.2f}")
            ax.axhline(y=setup['target_1'], color='blue', linestyle=':', label=f"TP1: {setup['target_1']:.2f}")
            
            if setup['target_2']:
                ax.axhline(y=setup['target_2'], color='purple', linestyle=':', label=f"TP2: {setup['target_2']:.2f}")
            
            # Set labels and title
            ax.set_title(f"{symbol} 1-Hour Chart - FVG Setup on {setup_date.strftime('%Y-%m-%d %H:%M')}")
            ax.set_xlabel('Date')
            ax.set_ylabel('Price')
            ax.set_xticks(range(0, len(plot_df), 5))
            ax.set_xticklabels([d.strftime('%Y-%m-%d\n%H:%M') for d in plot_df.index[::5]], rotation=45)
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # Save the plot
            plt.tight_layout()
            plt.savefig(f"{symbol}_fvg_{setup_date.strftime('%Y%m%d_%H%M')}.png")
            plt.close()
            
        except Exception as e:
            logger.error(f"Error creating plot for {symbol}: {e}")

    async def backtest_strategy(self, symbols: List[str], start_date: datetime, end_date: datetime, 
                              initial_capital: float = 100000.0) -> Dict:
        """Backtest the FVG strategy on historical data."""
        all_setups = await self.scan_market(symbols, start_date, end_date)
        
        # Initialize backtest results
        results = {
            'initial_capital': initial_capital,
            'final_capital': initial_capital,
            'trades': [],
            'win_rate': 0.0,
            'profit_factor': 0.0,
            'max_drawdown': 0.0
        }
        
        capital = initial_capital
        max_capital = initial_capital
        total_profit = 0.0
        total_loss = 0.0
        wins = 0
        losses = 0
        
        # Set a cutoff date to prevent look-ahead bias
        # Only use data available up to the current date
        current_date = datetime.now(UTC)
        
        for setup in all_setups:
            symbol = setup['symbol']
            entry_date = setup['date']
            entry_price = setup['entry']
            initial_sl = setup['initial_sl']
            tp1 = setup['target_1']
            tp2 = setup['target_2']
            
            # Skip setups that occur after our cutoff date
            if entry_date > current_date:
                logger.warning(f"Skipping future setup for {symbol} on {entry_date}")
                continue
                
            # Get data after entry for simulation
            # Only use data up to our cutoff date to prevent look-ahead bias
            simulation_end_date = min(end_date, current_date)
            df_5min = await self.get_5min_data(symbol, entry_date, simulation_end_date)
            if df_5min is None or len(df_5min) < 1:
                continue
                
            # Position sizing (risk 1% of capital per trade)
            risk_amount = capital * 0.01
            risk_per_share = entry_price - initial_sl
            if risk_per_share <= 0:
                continue
                
            shares = int(risk_amount / risk_per_share)
            
            if shares <= 0:
                continue
                
            # Simulate the trade
            entry_value = shares * entry_price
            trailing_sl = initial_sl
            highest_high = entry_price
            breakeven_hit = False
            tp1_hit = False
            exit_price = None
            exit_date = None
            
            # Apply realistic slippage to entry
            entry_price = entry_price * (1 + (np.random.random() * self.max_slippage_percent))
            
            for date, row in df_5min.iterrows():
                if date <= entry_date:
                    continue
                    
                highest_high = max(highest_high, row['high'])
                
                # Move to breakeven when price moves in favor by 1R
                if not breakeven_hit and (row['high'] - entry_price) >= risk_per_share:
                    trailing_sl = entry_price
                    breakeven_hit = True
                
                # Trail the stop loss
                if breakeven_hit:
                    trailing_sl = max(trailing_sl, highest_high - row['atr'])
                
                # Check if stopped out
                if row['low'] <= trailing_sl:
                    # Apply realistic slippage to exit
                    exit_price = trailing_sl * (1 - (np.random.random() * self.max_slippage_percent))
                    exit_date = date
                    break
                
                # Check if TP1 hit
                if not tp1_hit and row['high'] >= tp1:
                    # Take partial profits (50%)
                    exit_shares = shares // 2
                    remaining_shares = shares - exit_shares
                    
                    # Apply realistic slippage to partial exit
                    partial_exit_price = tp1 * (1 - (np.random.random() * self.max_slippage_percent))
                    
                    # Update position
                    profit = exit_shares * (partial_exit_price - entry_price) - (exit_shares * self.fee_per_share)
                    capital += profit
                    shares = remaining_shares
                    trailing_sl = max(trailing_sl, entry_price)  # Ensure at least breakeven
                    tp1_hit = True
                
                # Check if TP2 hit
                if tp1_hit and tp2 and row['high'] >= tp2:
                    # Apply realistic slippage to exit
                    exit_price = tp2 * (1 - (np.random.random() * self.max_slippage_percent))
                    exit_date = date
                    break
            
            # If not exited by end of data, use last price
            if exit_price is None and len(df_5min) > 0:
                exit_price = df_5min['close'].iloc[-1]
                exit_date = df_5min.index[-1]
            
            # Calculate trade result with fees
            if exit_price is not None:
                # Include trading fees
                fees = shares * self.fee_per_share
                trade_pnl = shares * (exit_price - entry_price) - fees
                capital += trade_pnl
                
                # Update statistics
                if trade_pnl > 0:
                    wins += 1
                    total_profit += trade_pnl
                else:
                    losses += 1
                    total_loss -= trade_pnl  # Convert to positive number
                
                # Track drawdown
                max_capital = max(max_capital, capital)
                drawdown = (max_capital - capital) / max_capital if max_capital > 0 else 0
                results['max_drawdown'] = max(results['max_drawdown'], drawdown)
                
                # Record trade
                results['trades'].append({
                    'symbol': symbol,
                    'entry_date': entry_date,
                    'exit_date': exit_date,
                    'entry_price': entry_price,
                    'exit_price': exit_price,
                    'shares': shares,
                    'pnl': trade_pnl,
                    'pnl_percent': trade_pnl / entry_value * 100 if entry_value > 0 else 0
                })
        
        # Calculate final statistics
        total_trades = wins + losses
        results['final_capital'] = capital
        results['win_rate'] = (wins / total_trades * 100) if total_trades > 0 else 0  # Fixed to percentage
        results['profit_factor'] = total_profit / total_loss if total_loss > 0 else float('inf')
        results['total_return'] = (capital - initial_capital) / initial_capital * 100
        results['total_trades'] = total_trades
        results['winning_trades'] = wins
        results['losing_trades'] = losses
        
        return results

    def generate_report(self, backtest_results: Dict) -> None:
        """Generate a comprehensive backtest report."""
        try:
            import matplotlib.pyplot as plt
            
            # Extract key metrics
            initial_capital = backtest_results['initial_capital']
            final_capital = backtest_results['final_capital']
            trades = backtest_results['trades']
            win_rate = backtest_results['win_rate']
            profit_factor = backtest_results['profit_factor']
            max_drawdown = backtest_results['max_drawdown']
            total_return = backtest_results['total_return']
            
            # Print summary
            print("===== BACKTEST RESULTS =====")
            print(f"Initial Capital: ${initial_capital:.2f}")
            print(f"Final Capital: ${final_capital:.2f}")
            print(f"Total Return: {total_return:.2f}%")
            print(f"Win Rate: {win_rate:.2f}%")
            print(f"Profit Factor: {profit_factor:.2f}")
            print(f"Max Drawdown: {max_drawdown:.2f}%")
            print(f"Total Trades: {len(trades)}")
            
            # Create equity curve
            if trades:
                plt.figure(figsize=(12, 6))
                
                # Calculate cumulative returns
                equity = [initial_capital]
                dates = []
                for trade in trades:
                    equity.append(equity[-1] + trade['pnl'])
                    dates.append(trade['exit_date'])
                
                # Plot equity curve
                plt.plot(range(len(equity)), equity)
                plt.title('Equity Curve')
                plt.xlabel('Trade Number')
                plt.ylabel('Capital ($)')
                plt.grid(True, alpha=0.3)
                plt.savefig('equity_curve.png')
                plt.close()
                
                # Plot trade P&L distribution
                plt.figure(figsize=(12, 6))
                pnls = [trade['pnl'] for trade in trades]
                plt.hist(pnls, bins=20)
                plt.title('Trade P&L Distribution')
                plt.xlabel('Profit/Loss ($)')
                plt.ylabel('Frequency')
                plt.grid(True, alpha=0.3)
                plt.savefig('pnl_distribution.png')
                plt.close()
                
                # Plot monthly returns if we have date information
                if dates:
                    monthly_returns = {}
                    for i, trade in enumerate(trades):
                        month_key = trade['exit_date'].strftime('%Y-%m')
                        if month_key not in monthly_returns:
                            monthly_returns[month_key] = 0
                        monthly_returns[month_key] += trade['pnl']
                    
                    if monthly_returns:
                        plt.figure(figsize=(14, 6))
                        months = list(monthly_returns.keys())
                        returns = list(monthly_returns.values())
                        plt.bar(months, returns)
                        plt.title('Monthly Returns')
                        plt.xlabel('Month')
                        plt.ylabel('Profit/Loss ($)')
                        plt.xticks(rotation=45)
                        plt.tight_layout()
                        plt.savefig('monthly_returns.png')
                        plt.close()
                
                # Save detailed trade log
                with open('trade_log.csv', 'w') as f:
                    f.write('Symbol,Entry Date,Exit Date,Entry Price,Exit Price,Shares,P&L,P&L %\n')
                    for trade in trades:
                        f.write(f"{trade['symbol']},{trade['entry_date']},{trade['exit_date']}," +
                                f"{trade['entry_price']:.2f},{trade['exit_price']:.2f},{trade['shares']}," +
                                f"{trade['pnl']:.2f},{trade['pnl_percent']:.2f}\n")
                
                print("Report files generated: equity_curve.png, pnl_distribution.png, monthly_returns.png, trade_log.csv")
        
        except Exception as e:
            logger.error(f"Error generating report: {e}")


async def main():
    # Define symbols to scan
    symbols = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'NVDA', 'AMD']
    
    # Define date range - use historical data only
    start_date = datetime(2023, 1, 1, tzinfo=UTC)
    end_date = datetime(2024, 1, 1, tzinfo=UTC)  # Use a past end date to avoid look-ahead bias
    
    # Create scanner instance
    scanner = MarketScanner(host='127.0.0.1', port=7497)
    
    try:
        # Connect to Interactive Brokers
        connected = await scanner.connect()
        if not connected:
            logger.error("Failed to connect to Interactive Brokers")
            return
        
        # Run backtest
        results = await scanner.backtest_strategy(symbols, start_date, end_date, initial_capital=100000.0)
        
        # Generate report
        scanner.generate_report(results)
        
    finally:
        # Disconnect from Interactive Brokers
        scanner.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
